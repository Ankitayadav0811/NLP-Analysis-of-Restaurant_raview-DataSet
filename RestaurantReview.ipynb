{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP(Natural language processing ) analysis of RESTAURANT  REVIEW dataset:\n",
    " * NLP is an area of computer science and artificial intelligence concerned with the interactions between computers and human (natural) languages. \n",
    " * NLP is a part of AI which overlaps with ML & DL to perform tasks. \n",
    "## step 1: \n",
    "* Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> step 2:</h1><p1>Import dataset with setting sep as '\\t' as columns are separated as tab space.</p1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Liked\n",
       "0                             Wow... Loved this place.      1\n",
       "1                                   Crust is not good.      0\n",
       "2            Not tasty and the texture was just nasty.      0\n",
       "3    Stopped by during the late May bank holiday of...      1\n",
       "4    The selection on the menu was great and so wer...      1\n",
       "..                                                 ...    ...\n",
       "995  I think food should have flavor and texture an...      0\n",
       "996                           Appetite instantly gone.      0\n",
       "997  Overall I was not impressed and would not go b...      0\n",
       "998  The whole experience was underwhelming, and I ...      0\n",
       "999  Then, as if I hadn't wasted enough of my life ...      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(r\"C:\\Users\\Ankita\\Desktop\\review.tsv\" , sep = \"\\t\")\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : \n",
    "<h2> Text Cleaning or Preprocessing :</h2>\n",
    "<h3>Remove Punctuations, Numbers :</h3> Punctuations, Numbers doesn’t help much in processong the given text, if included, they will just increase the size of bag of words that we will create as last step and decrase the efficency of algorithm.\n",
    "<h3>Stemming:</h3> Take roots of the word .for example:loved ----> lov,stopped ---->stop...etc.\n",
    "\n",
    "<h3>Convert each word into its lower case / upper case:</h3> it useless to have same words in different cases (eg: ‘good’ and ‘GOOD’ ).\n",
    "\n",
    "<h3>Tokenization: </h3> involves splitting sentences and words from the body of the text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_review = []\n",
    "text = dataset['Review'][0]\n",
    "for i in range(1000):\n",
    "    text = re.sub('[^a-zA-Z]',' ',dataset['Review'][i])\n",
    "    text = text.lower()\n",
    "    text = text.split()#tokenization\n",
    "    \n",
    "    #t1 = [word for word in text if not word in set(stopwords.words('english'))]\n",
    "    \n",
    "    text = [ps.stem(word) for word in text if not word in set(stopwords.words('english'))]\n",
    "    text = ' '.join(text)\n",
    "    clean_review.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4:\n",
    "<h2>Making the bag of words via sparse matrix</h2>\n",
    "\n",
    "* Take all the different words of reviews in the dataset without repeating of words.\n",
    "* One column for each word, therefore there are going to be many columns.\n",
    "* rows are reviews\n",
    "* If word is there in row of dataset of reviews, then the count of word will be there in row of bag of words under the column of the word.\n",
    "\n",
    "For this purpose we need CountVectorizer class from sklearn.feature_extraction.text.\n",
    "We can also set a max number of features as “max_features”. Do the training on the clean_review and then apply the same transformation to the clean_review “.fit_transform(clean_review)” and then convert it into an array.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] [1 0 0 1 1 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 1 0 1 1 1\n",
      " 0 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 0\n",
      " 0 0 0 1 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 1 0 1 0 0 0 0 1 1 0 0\n",
      " 0 0 1 1 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0 0 0 0 1\n",
      " 1 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 0 0 0 1 0 0 1 0 1 1 0 1 0 1 0 0\n",
      " 0 0 0 1 1 1 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1\n",
      " 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1\n",
      " 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 0 0 1 1\n",
      " 0 1 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1\n",
      " 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 0 1\n",
      " 1 1 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0\n",
      " 1 1 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 0 1 1 1 1 0\n",
      " 1 0 0 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 1 0 1\n",
      " 0 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 1 1 1 0 0\n",
      " 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1\n",
      " 1 0 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 0 0\n",
      " 1 1 1 0 1 0 1 0 1 0 1 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 1 1 0 1 0 1 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1\n",
      " 1 0 0 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 1\n",
      " 0 0 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 0 0\n",
      " 1 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1\n",
      " 0 1 1 0 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0\n",
      " 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer( max_features = 900)\n",
    "X = cv.fit_transform(clean_review)\n",
    "X = X.toarray()\n",
    "\n",
    "#x has 1000 rows representing 1000 reviews . But the col are limited \n",
    "#to 500 set by max_feature parameter. whlile processing textual data we can \n",
    "#get large amount of col. we sort these col by frequency and then keep only\n",
    "#frequent col representing few frequent words.\n",
    "\n",
    "y = dataset['Liked'].values\n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5:\n",
    "</h3>Fitting Predictive Model (here I choose 5 classes):</h3>\n",
    "\n",
    "* Fit the model via .fit() method with attributes X and y.\n",
    "* And check the accuracy score on whole DataSet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.939\n",
      "0.806\n",
      "0.955\n",
      "0.847\n",
      "0.995\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtf = DecisionTreeClassifier()\n",
    "\n",
    "log_reg.fit(X,y)\n",
    "knn.fit(X,y)\n",
    "svm.fit(X,y)\n",
    "nb.fit(X,y)\n",
    "dtf.fit(X,y)\n",
    "\n",
    "print(log_reg.score(X,y))\n",
    "print(knn.score(X,y))\n",
    "print(svm.score(X,y))\n",
    "print(nb.score(X,y))\n",
    "print(dtf.score(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 : \n",
    "* Splitting into Training and Test set. For this, we need class train_test_split from sklearn.cross_validation. Split can be made 70/30 or 80/20 or 85/15 or 75/25, here I choose 75/25 via “test_size”.\n",
    "* Fitting a Predictive Model (here I choose 5 classes).\n",
    "    Fit the model via .fit() method with attributes X_train and y_train.\n",
    "* And then check the Accuracy score on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.776\n",
      "0.672\n",
      "0.78\n",
      "0.676\n",
      "0.728\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test , y_train,y_test = train_test_split(X,y,test_size = 0.25)\n",
    "\n",
    "model1 = log_reg.fit(X_train,y_train)\n",
    "model2 = knn.fit(X_train,y_train)\n",
    "model3 = svm.fit(X_train,y_train)\n",
    "model4 = nb.fit(X_train,y_train)\n",
    "model5 = dtf.fit(X_train,y_train)\n",
    "\n",
    "print(log_reg.score(X_test,y_test))\n",
    "print(knn.score(X_test,y_test))\n",
    "print(svm.score(X_test,y_test))\n",
    "print(nb.score(X_test,y_test))\n",
    "print(dtf.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 0 1 1 1 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 1 0 1 1 1\n",
      " 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 1 1 1 1 0 0 0 1 0 1 0 0 0\n",
      " 0 1 0 0 0 1 1 1 0 0 1 1 0 1 1 1 0 1 0 1 0 1 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0\n",
      " 1 1 1 0 1 0 0 1 1 0 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1 0 1\n",
      " 1 1 0 1 1 1 1 0 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1\n",
      " 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 1 1 1\n",
      " 0 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1] [1 0 0 0 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 0 0 1 0 1 0 0 0 1 0 1 1 1\n",
      " 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0\n",
      " 0 1 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 1 1 0 1 0\n",
      " 1 1 1 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 1 0 0 0 0 1 0 1 0 0 1\n",
      " 0 1 0 1 0 0 1 0 1 1 0 1 0 1 1 0 0 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 1 1 0 0 1\n",
      " 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0\n",
      " 1 0 1 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1] [1 0 0 1 0 0 0 1 1 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 1 0 0 1 0\n",
      " 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 1 0 0 0\n",
      " 0 1 0 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0\n",
      " 1 1 1 0 1 0 0 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1\n",
      " 0 1 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1\n",
      " 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1\n",
      " 0 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0 1 1] [1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1\n",
      " 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0\n",
      " 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 1 1 1 0 0 0 0\n",
      " 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1\n",
      " 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0 0 1 0 1 0 0 1 1 1 0 0 0 1 1 1 1 0 0 1 1 1 1\n",
      " 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 1] [1 0 1 1 0 0 0 1 1 1 0 0 1 1 1 0 0 0 0 1 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1\n",
      " 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 1 1 1 1 0 1 1 1 0 0 0\n",
      " 1 1 1 0 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 1 0 1 0 1 0 1 0 1 1 0 1 1 0 1\n",
      " 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1\n",
      " 1 1 1 0 0 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1 1 1 0 0 0 1\n",
      " 0 0 1 1 0 0 1 1 0 1 0 1 1 0 1 0 0 0 1 1 0 0 0 0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results \n",
    "y_pred1 = model1.predict(X_test) \n",
    "y_pred2 = model2.predict(X_test) \n",
    "y_pred3 = model3.predict(X_test) \n",
    "y_pred4 = model4.predict(X_test) \n",
    "y_pred5 = model5.predict(X_test) \n",
    "  \n",
    "print(y_pred1, y_pred2, y_pred3, y_pred4, y_pred5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: \n",
    "To know the accuracy we need confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 91  30]\n",
      " [ 26 103]] [[88 33]\n",
      " [49 80]] [[103  18]\n",
      " [ 37  92]] [[ 61  60]\n",
      " [ 21 108]] [[ 79  42]\n",
      " [ 26 103]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "  \n",
    "cm1 = confusion_matrix(y_test, y_pred1) \n",
    "cm2 = confusion_matrix(y_test, y_pred2) \n",
    "cm3 = confusion_matrix(y_test, y_pred3) \n",
    "cm4 = confusion_matrix(y_test, y_pred4) \n",
    "cm5 = confusion_matrix(y_test, y_pred5) \n",
    "\n",
    "print(cm1, cm2, cm3, cm4, cm5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 :\n",
    "Precision, Recall, f1 scores on macro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7761069340016709 0.7752578640527901 0.775482712168837\n",
      "0.6751501840966345 0.6737138830162086 0.6716637837145236\n",
      "0.7860389610389611 0.7822089819975655 0.7795732538193945\n",
      "0.6933797909407666 0.67067076686527 0.664128974473802\n",
      "0.7313628899835796 0.7256710871932859 0.7254699308830179\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "p1 = precision_score(y_test, y_pred1,average = 'macro')\n",
    "r1 = recall_score(y_test, y_pred1,average = 'macro')\n",
    "f1 = f1_score(y_test, y_pred1,average = 'macro')\n",
    "\n",
    "p2 = precision_score(y_test, y_pred2,average = 'macro')\n",
    "r2 = recall_score(y_test, y_pred2,average = 'macro')\n",
    "f2 = f1_score(y_test, y_pred2,average = 'macro')\n",
    "\n",
    "p3 = precision_score(y_test, y_pred3,average = 'macro')\n",
    "r3 = recall_score(y_test, y_pred3,average = 'macro')\n",
    "f3 = f1_score(y_test, y_pred3,average = 'macro')\n",
    "\n",
    "p4 = precision_score(y_test, y_pred4,average = 'macro')\n",
    "r4 = recall_score(y_test, y_pred4,average = 'macro')\n",
    "f4 = f1_score(y_test, y_pred4,average = 'macro')\n",
    "\n",
    "p5 = precision_score(y_test, y_pred5,average = 'macro')\n",
    "r5 = recall_score(y_test, y_pred5,average = 'macro')\n",
    "f5 = f1_score(y_test, y_pred5,average = 'macro')\n",
    "\n",
    "print(p1, r1, f1)\n",
    "print(p2, r2, f2)\n",
    "print(p3, r3, f3)\n",
    "print(p4, r4, f4)\n",
    "print(p5, r5, f5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9:\n",
    "Precision, Recall,f1 scores on micro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.776 0.776 0.776\n",
      "0.672 0.672 0.672\n",
      "0.78 0.78 0.78\n",
      "0.676 0.676 0.676\n",
      "0.728 0.728 0.728\n"
     ]
    }
   ],
   "source": [
    "p1 = precision_score(y_test, y_pred1,average = 'micro')\n",
    "r1 = recall_score(y_test, y_pred1,average = 'micro')\n",
    "f1 = f1_score(y_test, y_pred1,average = 'micro')\n",
    "\n",
    "p2 = precision_score(y_test, y_pred2,average = 'micro')\n",
    "r2 = recall_score(y_test, y_pred2,average = 'micro')\n",
    "f2 = f1_score(y_test, y_pred2,average = 'micro')\n",
    "\n",
    "p3 = precision_score(y_test, y_pred3,average = 'micro')\n",
    "r3 = recall_score(y_test, y_pred3,average = 'micro')\n",
    "f3 = f1_score(y_test, y_pred3,average = 'micro')\n",
    "\n",
    "p4 = precision_score(y_test, y_pred4,average = 'micro')\n",
    "r4 = recall_score(y_test, y_pred4,average = 'micro')\n",
    "f4 = f1_score(y_test, y_pred4,average = 'micro')\n",
    "\n",
    "p5 = precision_score(y_test, y_pred5,average = 'micro')\n",
    "r5 = recall_score(y_test, y_pred5,average = 'micro')\n",
    "f5 = f1_score(y_test, y_pred5,average = 'micro')\n",
    "\n",
    "print(p1, r1, f1)\n",
    "print(p2, r2, f2)\n",
    "print(p3, r3, f3)\n",
    "print(p4, r4, f4)\n",
    "print(p5, r5, f5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
